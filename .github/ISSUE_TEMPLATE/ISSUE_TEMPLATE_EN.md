---
name: English Issue Template
about: Issues related to this project
---

Thank you for using the Issue submission template. Please follow the steps below to provide relevant information. We will prioritize issues with relatively complete information. Your cooperation is appreciated.

*Hint: Fill in the [ ] with an x to mark it as checked. Delete any option that is not related to this issue.

### Describe the issue in detail

*Please describe the problem you encountered as specifically as possible. This will help us locate the issue more quickly.*

### Provide a screenshot or log of the issue

*(If necessary) Please provide a text log or screenshot to help us better understand the issue details.*


### MUST check

- [ ] Base model: LLaMA or Alpaca? **(delete irrelevant option)**
- [ ] Issue type:
  - Download issue
  - Model conversion and merging issue
  - Model inference issue (ðŸ¤— transformers)
  - Model quantization and deployment issue (llama.cpp, text-generation-webui, LlamaChat)
  - Performance issue
  - Other issues
- [ ] Due to frequent dependency updates, please ensure you have followed the steps in our [Wiki](https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki)
- [ ] I have read the [FAQ section](https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/FAQ) AND searched for similar issues and did not find a similar problem or solution
- [ ] Third-party plugin issues: e.g., [llama.cpp](https://github.com/ggerganov/llama.cpp), [text-generation-webui](https://github.com/oobabooga/text-generation-webui), [LlamaChat](https://github.com/alexrozanski/LlamaChat), we recommend checking the corresponding project for solutions
